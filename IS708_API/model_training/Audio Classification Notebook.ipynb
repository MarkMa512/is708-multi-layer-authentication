{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39b2431",
   "metadata": {},
   "source": [
    "# Audio Classification using Support vector machines (SVMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e8ee07",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f8e85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Relevant libraries\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "389474fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load audio clips and extract features\n",
    "def load_and_extract_features(audio_folder_path:str, n_mfcc=20)->list:\n",
    "    \"\"\"\n",
    "    Load audio clips from a folder and extract MFCC features.\n",
    "    \n",
    "    Parameters:\n",
    "        - audio_folder_path (str): Path to the folder containing subfolders correspond to each person (class) and each containing audio clips.\n",
    "        - n_mfcc (int): Number of Mel-frequency cepstral coefficients (MFCC) to extract.\n",
    "    \n",
    "    Returns:\n",
    "        - X (list): Extracted features (shape: [[n_samples, n_mfcc]]).\n",
    "        - y (list): Labels corresponding to the audio clips (shape: [n_samples,]).\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for label in range(1, 6):\n",
    "        folder_path = f\"{audio_folder_path}/{label}\"\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if not file_name.startswith('.'): \n",
    "                file_path = f\"{folder_path}/{file_name}\"\n",
    "                # print (file_path)\n",
    "                # Load audio clip\n",
    "                signal, sr = librosa.load(file_path, duration=3.0)  # Set duration to 3 seconds\n",
    "                # Extract MFCC features\n",
    "                mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)\n",
    "                # Flatten the list\n",
    "                mfcc_flattened=mfcc.T.flatten().tolist()\n",
    "                # print(len(mfcc_flattened))\n",
    "                # Append features and label to X and y\n",
    "                X.append(mfcc_flattened)\n",
    "                y.append(label)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Call the function to load and extract features from audio clips\n",
    "audio_folder_path = \"Audio\"  # Path to the folder containing the audio clips\n",
    "X, y = load_and_extract_features(audio_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5aa86af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc89e0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ca23065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize an SVM classifier, using linear kernel for the best performance\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "\n",
    "# Pad or truncate MFCC features to a consistent length\n",
    "X_train = pad_sequences(X_train, maxlen=2500, dtype='float32', padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=2500, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "# Standardize the data\n",
    "# REMOVED AS IT IS CAUSING ACCURACY ISSUE\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Check the size of the data\n",
    "# print(len(X_train))\n",
    "# print(len(X_test))\n",
    "\n",
    "# print(len(X_train[3]))\n",
    "# print(len(X_test[5]))\n",
    "\n",
    "# print (len(y_train))\n",
    "# print (len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a10960f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Train the SVM classifier on the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the testing data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db2fab",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7fdf9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def predict_new_audio(new_audio_path:str, svm:object, n_mfcc=20)->int:\n",
    "    input_list = []\n",
    "    signal_new, sr_new = librosa.load(new_audio_path, duration=3.0)\n",
    "    mfcc_new = librosa.feature.mfcc(y=signal_new, sr=sr_new, n_mfcc=n_mfcc)\n",
    "    mfcc_flattened=mfcc_new.T.flatten().tolist()\n",
    "    input_list.append(mfcc_flattened)\n",
    "    input_list = pad_sequences(input_list, maxlen=2500, dtype='float32', padding='post', truncating='post')\n",
    "    y_pred = svm.predict(input_list)\n",
    "    return y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdcb801",
   "metadata": {},
   "source": [
    "## Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3f05e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(predict_new_audio(\"Audio/1/1677931349968.mp3\", svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9f4d6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(predict_new_audio(\"Audio/4/1678429656280.mp3\", svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fe6beca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(predict_new_audio(\"Audio/2/1677933179540.mp3\", svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb0bafe",
   "metadata": {},
   "source": [
    "## Export the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2ff3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "filename = 'audio_svm_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(svm, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e480e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'audio_svm_model.pkl'\n",
    "with open(filename, 'rb') as file:\n",
    "    clf = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
